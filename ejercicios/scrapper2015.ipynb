{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio integrador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El enunciado: WEB SCRAPING\n",
    "\n",
    "Existen muchas formas de utilizar los buscadores de Internet para encontrar cosas; uno muy\n",
    "interesante para los entusiastas de las descargas es la de obtener música de forma directa.\n",
    "\n",
    "Por lo general la música (en forma de archivos) disponible desde un servidor Apache presenta\n",
    "determinadas palabras en las paginas que al ser indexadas por los buscadores permiten posteriormente formular consultas, combinando estas palabras y lo que efectivamente se esta\n",
    "buscando de un archivo de música (generalmente el nombre de la canción).\n",
    "\n",
    "De este modo, un hipotético fanático de Ricardo Arjona podría obtener música simplemente\n",
    "con:\n",
    "\n",
    "```bash\n",
    "intitle:\"index of\" \"Apache Server\" \"Parent Directory\" arjona\n",
    "```\n",
    "\n",
    "...o refinando y ajustando un poco mas\n",
    "\n",
    "```bash\n",
    "-inurl: (htm|html|php) intitle:\"index of\" +\"last modified\" +\"parent directory\" +description +size +(wma|mp3) arjona\n",
    "```\n",
    "\n",
    "...y navegar entre los primeros resultados de la búsqueda para descargar un archivo de audio.\n",
    "\n",
    "Si dicho fanático quisiera bajar la discografía completa del cantautor de alguna de las urls\n",
    "encontradas podría utilizar una herramienta como wget para automatizar la descargar de\n",
    "todos los archivos de audio.\n",
    "\n",
    "```bash\n",
    "# !/usr/bin/env bash\n",
    "wget -r - l1 - np -A . mp3 \" $1 \"\n",
    "```\n",
    "\n",
    "En el ejemplo anterior wget descarga recursivamente (nivel 1) sin subir a la ruta padre todos los mp3s que se obtengan de la url pasada como parámetro.\n",
    "\n",
    "Considerando que las paginas generadas por Apache son dinámicas, osea que eventualmente\n",
    "podrian cambiar cuando el administrador del sitio modifique el directorio que contiene a los\n",
    "archivos y por sobretodo que no a todos tenemos los mismos gustos musicales.\n",
    "\n",
    "Utilice un lenguaje de programación que, de forma simple, provea funciones para obtener\n",
    "contenido de internet y codifique una herramienta que descargue música."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La Solucion: web_scrapper.py\n",
    "\n",
    "```python\n",
    "#!/usr/bin/python\n",
    "# \"Copyright (C) 2015 Matías Iglesias\"\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError, URLError\n",
    "\n",
    "ARCHIVO_FUENTES = \"fuentes.txt\"\n",
    "\n",
    "\n",
    "def obtener_fuentes():\n",
    "    # TODO: Manejar el archivo en un bloque with\n",
    "    f = open(ARCHIVO_FUENTES, \"r\")\n",
    "    # TODO: Usar readlines del objeto file\n",
    "    fuentes = f.read().splitlines(False)\n",
    "    f.close()\n",
    "    return fuentes\n",
    "\n",
    "\n",
    "def scrapp_source(source, search_for, depth=1):\n",
    "    # print(\"Abro URL: \" + source + \" Profundidad: \" + str(depth))\n",
    "    try:\n",
    "        # TODO: Manejar el request en un bloque with\n",
    "        f = urllib.request.urlopen(source)\n",
    "        #print f.read()\n",
    "        urls = obtener_urls(f.read().decode(\"utf-8\"))\n",
    "        for url in urls:\n",
    "            match = re.search(r'\\/', url)\n",
    "            if match and url != \"/\":\n",
    "                #print url + \" es un directorio\"\n",
    "                if depth > 1:\n",
    "                    # print(\"Busco recursivamente en \" + source + \" subidrectorio \" + url)\n",
    "                    scrapp_source(source + url, search_for, depth - 1)\n",
    "            else:\n",
    "                #print url + \" es un archivo\"\n",
    "                match = re.search(search_for.lower(), url.lower())\n",
    "                if match:\n",
    "                    # print(\"Bajo \" + source + url)\n",
    "                    # FIXME: file_tmp nunca es cerrado, manejar el request en un bloque with\n",
    "                    file_tmp = urllib.request.urlopen(source + url)\n",
    "                    # TODO: Manejar el request en un bloque with\n",
    "                    local_file = open(url, \"wb\")\n",
    "                    local_file.write(file_tmp.read())\n",
    "                    local_file.close()\n",
    "        f.close()\n",
    "        #print urls\n",
    "    except HTTPError as e:\n",
    "        print(\"Ocurrio un error\")\n",
    "        print(e.code)\n",
    "    except URLError as e:\n",
    "        print(\"Ocurrio un error\")\n",
    "        print(e.reason)\n",
    "\n",
    "\n",
    "def obtener_urls(http):\n",
    "    # print(\"HTTP Crudo \" + http)\n",
    "    urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', http)\n",
    "    return urls\n",
    "\n",
    "depth = 1\n",
    "search_for = None\n",
    "\n",
    "# TODO: Agregar el bloque if __name__ == '__main__': para trabajar con este \n",
    "# script de manera mas limpia ver http://www.artima.com/weblogs/viewpost.jsp?thread=4829\n",
    "\n",
    "try:\n",
    "    search_for = sys.argv[1]\n",
    "    depth = int(sys.argv[2])\n",
    "except IndexError as ex:\n",
    "    if search_for is None:\n",
    "        print(\"\"\"\\\n",
    "Uso: python web_scrapper.py search [depth]\"\"\")\n",
    "except ValueError as ex:\n",
    "    print(\"\"\"\\\n",
    "Uso: python web_scrapper.py search [depth]\n",
    "depth debe ser un entero\"\"\")\n",
    "\n",
    "if search_for is not None:\n",
    "    fuentes = obtener_fuentes()\n",
    "    # print fuentes\n",
    "    for fuente in fuentes:\n",
    "        # print(\"Scrappeo \" + fuente)\n",
    "        scrapp_source(fuente, search_for, depth)\n",
    "```\n",
    "\n",
    "### Contenido del archivo ``fuentes.txt``\n",
    "\n",
    "```text\n",
    "http://quitmumbling.com/public_html/wp-content/uploads/\n",
    "http://mhoerner.dyndns.org\n",
    "http://yottabi.com/musica/\n",
    "http://yottabi.com/musica/ARJONA/\n",
    "http://carlosjuez.com/temporal/\n",
    "http://metropolisfm.com/musica/\n",
    "http://floatingworldweb.com/MUSIC/@ELECTRONICA/@DJ%20MIXES/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observaciones\n",
    "\n",
    "El script presentado por el alumno (Matías) hace lo que tiene que hacer y descarga música de internet veamos ahora como abordo la solucion y como podemos mejorarla (no funcionamente, sino mas bien pythonicamente).\n",
    "\n",
    "Matías introduce dos librerias o modulos nuevos de python, ``re`` y ``urllib``, antes de realizar la actividad veamos que hacen estos dos modulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [re](https://docs.python.org/3.5/library/re.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# El patron encuentra las ocurrencias \"cadena\"\n",
    "re.findall(r'cadena', 'una cadena con espacios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# El patron encuentra las ocurrencias de un espacio\n",
    "re.findall(r'\\s', 'una    cadena    con   espacios,  con  muchos  espacios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# El patron encuentra las ocurrencias de un espacio o mas\n",
    "re.findall(r'\\s+', 'una    cadena    con   espacios,  con  muchos  espacios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# El patron encuentra las ocurrencias de un caracter o mas\n",
    "re.findall(r'\\w+', 'una    cadena    con   espacios,  con  muchos  espacios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# El patron encuentra las ocurrencias de un caracter a o s seguido de uno o mas espacios\n",
    "re.findall(r'[as]\\s+', 'una    cadena    con   espacios,  con  muchos  espacios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# El patron encuentra las ocurrencias de un caracter a o s seguido de cero o mas espacios\n",
    "re.findall(r'[as]\\s*', 'una    cadena    con   espacios,  con  muchos  espacios')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [urllib](https://docs.python.org/3.5/library/urllib.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "with urllib.request.urlopen('http://www.google.com') as r:\n",
    "    r.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividades\n",
    "\n",
    "1. Ejecutar el script\n",
    "1. Leer e interpetar el código buscar en la ayuda respectiva usando spyder\n",
    "1. Este script funciona en python 2 pero no en python 3, descomentar todos los print's de debug y arreglar los que correspondan para que funcionen en python 3\n",
    "1. Alternar la ejecucion del script con comentar y descomentar prints hasta que estemos comodos con la informacion de debug que se nos presenta\n",
    "1. Implementar los TODO y los FIXME\n",
    "1. Mejorar el bloque try...except de la funcion scrapp_source, identificar y trabajar sólo sobre los posibles puntos de falla no sobre todo el bloque de la función\n",
    "1. La funcion scrapp_source, toma dos caminos alternos para cada url dependiendo del tipo de url que corresponda, identificar esos caminos e implementarlos como funciones\n",
    "1. Modularizar el codigo creando los modulos y/o paquetes correspondientes para separar la logica de manejar archivos (leer y escribir) y la de obtener urls posteriormente crear ``main.py`` y trabajar con los modulos y/o paquetes obtenidos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
